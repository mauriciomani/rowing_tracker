{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8a8c740-911a-4f92-a35f-9a7e81bd1026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.8.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.8 MB)\n",
      "     |████████████████████████████████| 32.8 MB 7.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: absl-py in ./venv/lib/python3.8/site-packages (from mediapipe) (0.15.0)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.8/site-packages (from mediapipe) (1.15.0)\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.5.4.60-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (66.5 MB)\n",
      "     |████████████████████████████████| 66.5 MB 26.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wheel in ./venv/lib/python3.8/site-packages (from mediapipe) (0.37.0)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.8/site-packages (from mediapipe) (3.5.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in ./venv/lib/python3.8/site-packages (from mediapipe) (3.19.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in ./venv/lib/python3.8/site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.8/site-packages (from mediapipe) (1.19.5)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.8/site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./venv/lib/python3.8/site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.8/site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.8/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.8/site-packages (from matplotlib->mediapipe) (4.28.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.8/site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: setuptools-scm>=4 in ./venv/lib/python3.8/site-packages (from matplotlib->mediapipe) (6.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./venv/lib/python3.8/site-packages (from matplotlib->mediapipe) (3.0.6)\n",
      "Requirement already satisfied: tomli>=1.0.0 in ./venv/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib->mediapipe) (1.2.2)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib->mediapipe) (59.4.0)\n",
      "Installing collected packages: opencv-contrib-python, mediapipe\n",
      "Successfully installed mediapipe-0.8.9 opencv-contrib-python-4.5.4.60\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd99c03-4e4b-4f53-94d4-740f3c81f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# We want the pose estimation\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77fc9504-16e4-4621-9ac8-6e484deb77cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_joint_angle(a, b, c):\n",
    "    \"\"\"\n",
    "    This function takes 3 points and form an angle over those.\n",
    "    Arctan can convert x,y plane into an angle and a radius: arctan(y/x).\n",
    "    Necessary to change radians to angles\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : int\n",
    "        First point \n",
    "    b : int\n",
    "        Second point\n",
    "    c : int\n",
    "        Third point\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Angle of the positions\n",
    "    \"\"\"\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180:\n",
    "        angle = 360 - angle\n",
    "    \n",
    "    return(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28cc9637-7c76-4af1-b867-7f1e08735ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Image\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    frame = cv2.imread(\"../help/img/bad_posture.png\")\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = pose.process(image)\n",
    "    \n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image,\n",
    "                              results.pose_landmarks, \n",
    "                              mp_pose.POSE_CONNECTIONS, \n",
    "                              mp_drawing.DrawingSpec(color=(245, 117, 66), \n",
    "                                                     thickness=2, \n",
    "                                                     circle_radius=2))\n",
    "    \n",
    "    cv2.imshow('', image)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31562db8-cd61-4896-9063-1a0871eefc13",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition\n",
      "transition\n",
      "transition\n",
      "transition\n",
      "transition\n",
      "transition\n",
      "transition\n",
      "transition\n",
      "transition\n",
      "transition\n",
      "transition\n"
     ]
    }
   ],
   "source": [
    "### Webcam\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "### Video\n",
    "cap = cv2.VideoCapture('../videos/rowing4.mp4')\n",
    "position = \"right\" #\"left\"\n",
    "# legs straight: 1, otherwise 0.\n",
    "legs_track = []\n",
    "# arms straight: 1, otherwise 0.\n",
    "arms_track = []\n",
    "# This values might be needed to tweak\n",
    "min_legs_angle_threshold = 160\n",
    "min_arms_angle_threshold = 150\n",
    "\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:  \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "                \n",
    "        results = pose.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            if position == \"left\":\n",
    "                # Extract left part of the body\n",
    "                hip = landmarks[23]\n",
    "                knee = landmarks[25]\n",
    "                ankle = landmarks[27]\n",
    "                shoulder = landmarks[11]\n",
    "                elbow = landmarks[13]\n",
    "                wrist = landmarks[15]\n",
    "            else:\n",
    "                # Extract right part of the body\n",
    "                hip = landmarks[24]\n",
    "                knee = landmarks[26]\n",
    "                ankle = landmarks[28]\n",
    "                shoulder = landmarks[12]\n",
    "                elbow = landmarks[14]\n",
    "                wrist = landmarks[16]\n",
    "                \n",
    "            hip_visibility = hip.visibility\n",
    "            knee_visibility = knee.visibility\n",
    "            ankle_visibility = ankle.visibility\n",
    "            shoulder_visibility = shoulder.visibility\n",
    "            elbow_visibility = elbow.visibility\n",
    "            wrist_visibility = wrist.visibility\n",
    "                        \n",
    "            if (hip_visibility >= 0.4 and \n",
    "                knee_visibility >= 0.4 and \n",
    "                ankle_visibility >= 0.4 and\n",
    "                shoulder_visibility >= 0.4 and \n",
    "                elbow_visibility >= 0.4 and \n",
    "                wrist_visibility >= 0.4):\n",
    "                # Only calculate if visbility\n",
    "                hip = [hip.x, hip.y]\n",
    "                knee = [knee.x, knee.y]\n",
    "                ankle = [ankle.x, ankle.y]\n",
    "                shoulder = [shoulder.x, shoulder.y]\n",
    "                elbow = [elbow.x, elbow.y]\n",
    "                wrist = [wrist.x, wrist.y]\n",
    "\n",
    "                # Extract angles\n",
    "                angle_leg = three_joint_angle(hip, knee, ankle)\n",
    "                angle_arm = three_joint_angle(shoulder, elbow, wrist)\n",
    "                \n",
    "                if angle_leg >= min_legs_angle_threshold:\n",
    "                    # legs straight\n",
    "                    legs_track.append(1)\n",
    "                else:\n",
    "                    legs_track.append(0)\n",
    "                \n",
    "                if angle_arm >= min_arms_angle_threshold:\n",
    "                    # arms straight\n",
    "                    arms_track.append(1)\n",
    "                else:\n",
    "                    arms_track.append(0)\n",
    "            \n",
    "                if len(legs_track) > 2:\n",
    "                    if legs_track[-1] != legs_track[-2] and legs_track[-1] != legs_track[-3]:\n",
    "                        # Would keep track of instant transition\n",
    "                        # A stroke would be completed by 2 transitions, going backward and then forward.\n",
    "                        print(\"transition\")\n",
    "                        legs_track = []\n",
    "                    else:\n",
    "                        # If legs not straight and arms not straight: ERROR\n",
    "                        if len(arms_track) > 2:\n",
    "                            if arms_track[-1] != arms_track[-2] and arms_track[-1] != arms_track[-3]:\n",
    "                                # Would keep track of instant transition\n",
    "                                # A stroke would be completed by 2 transitions, going backward and then forward.\n",
    "                                # print(\"transition\")\n",
    "                                arms_track = []\n",
    "                            elif legs_track[-1] == 0 and arms_track[-1] == 0:\n",
    "                                # If legs not straight and arm not straight then warning\n",
    "                                print(\"Warning\")\n",
    "                    # Only when legs straight you should pull elbows back\n",
    "                    # 0 and 1 legs not straight and arms straight\n",
    "                    # 1 and 0 legs straight and arms not straight\n",
    "                    # 1 and 1 legs straight and arms straight (should be instantaneous)\n",
    "                    # 0 and 0 legs not straight and arms not straight warning\n",
    "                                            \n",
    "            cv2.putText(image, str(angle_leg), tuple(np.multiply(hip, [1280, 720]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(angle_arm), tuple(np.multiply(elbow, [1280, 720]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, \n",
    "                                  results.pose_landmarks, \n",
    "                                  mp_pose.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(245, 117, 66), \n",
    "                                                         thickness=2, \n",
    "                                                         circle_radius=2))\n",
    "        \n",
    "        cv2.imshow(\"mediapipe test\", image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
